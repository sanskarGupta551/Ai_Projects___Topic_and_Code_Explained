{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o96JyiCtPDjn"
      },
      "source": [
        "* [Ai Long form Story Generator with Varied Context](#1)\n",
        "    * [O. Project Explained](#2)\n",
        "    * [A. Story Generation with Varied Context](#3)\n",
        "    * [B. Exploring Effectiveness of Greater Context](#4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ2QWDv6PDjp"
      },
      "source": [
        "# **Ai `Long` form `Story` Generator with `Varied Context`** <a id=\"1\"></a>\n",
        "\n",
        "![Image](https://quotefancy.com/media/wallpaper/3840x2160/6840-Stephen-King-Quote-If-you-want-to-be-a-writer-you-must-do-two.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhEpyYjiPDjp"
      },
      "source": [
        "***\n",
        "\n",
        "## **O. Project Explained** <a id=\"2\"></a>\n",
        "\n",
        "### **Objective**\n",
        "\n",
        "* In this project, we will have `two objectives` -\n",
        "\n",
        "##### **`1. Story Generation with Varied Context`**\n",
        "\n",
        "* Perform `Story Generation` by taking in varied levels of `Context` as inputs.\n",
        "\n",
        "##### **`2. Exploring Effectiveness of Greater Context`**\n",
        "\n",
        "* Explore how `Effective` is consumption of `more Context` in Generating Better Stories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "'''\n",
        "\n",
        "### **Workflow**\n",
        "\n",
        "* In `short`, we will `generate Story` from a model with `more context`.\n",
        "\n",
        "* In `long`, we will `use` various different `NLP models` and go through the following `steps` -\n",
        "\n",
        "#### **A. Story Generation with Varied Context**\n",
        "\n",
        "##### **1. Import the Model**\n",
        "\n",
        "* We will `import` model that can Generator Stories from `Prompts`.\n",
        "\n",
        "##### **2. Generate Stories with Varied Amount of Context**\n",
        "\n",
        "* Then we will `generate stories` appending Prompts with `three` levels of `Context` -\n",
        "  * A. No Context\n",
        "  * B. Previous Event\n",
        "  * C. Summary of Previous Chapter\n",
        "\n",
        "#### **B. Exploring Effectiveness of Greater Context**\n",
        "\n",
        "* In the End, we will `Benchmark` the Stories Generated and also `Compare` the effectiveness of more `Context` ourselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXa5pxp-PDjq"
      },
      "source": [
        "***\n",
        "\n",
        "## **A. Story Generation with Varied Context** <a id=\"3\"></a>\n",
        "\n",
        "* For this project, we will `compare` the effects of `Context` on following `three` `models` - \n",
        "\n",
        "1. [bigscience/bloom-1b7](https://huggingface.co/bigscience/bloom-7b1) - \n",
        "\n",
        "* An `autoregressive` Large Language Model (`LLM`) trained on vast amounts of text data using industrial-scale computational resources. \n",
        "* It is capable of generating `coherent text` in `46` `natural` languages and `13 programming languages` that is hardly distinguishable from text written by humans.\n",
        "\n",
        "![Image](https://huggingface.co/blog/assets/86_bloom/thumbnail-2.png)\n",
        "\n",
        "2. [EleutherAI/gpt-neo-2.7B](https://huggingface.co/EleutherAI/gpt-neo-2.7B) - \n",
        "\n",
        "* `GPT-Neo 2.7B` is a transformer model designed using EleutherAI's replication of the `GPT-3` architecture. \n",
        "* `GPT-Neo` refers to the class of models, while `2.7B` represents the number of parameters of this particular pre-trained model.\n",
        "\n",
        "![Image](https://thumbnails.huggingface.co/social-thumbnails/models/EleutherAI/gpt-neo-2.7B.png)\n",
        "\n",
        "3. [databricks/dolly-v2-3b](https://huggingface.co/databricks/dolly-v2-3b) - \n",
        "\n",
        "* A `3 billion` parameter causal language model created by `Databricks` that is derived from [EleutherAI/pythia-3b](https://huggingface.co/EleutherAI/pythia-3b) and `fine-tuned` on a ~15K record instruction corpus generated by `Databrick`. \n",
        "\n",
        "![Image](https://ciolook.com/wp-content/uploads/2023/04/Dolly-2.0-the-first-open-instruction-following-LLM-for-commercial-use-is-released-by-Databricks.jpg)\n",
        "\n",
        "* With this brief introduction, let's begin `Generating Stories` - "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7turzZAPDjq"
      },
      "outputs": [],
      "source": [
        "# Takes context from previously generated story to generate more contexual and\n",
        "# coherent story for whatever length required using loops."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "'''\n",
        "\n",
        "### **1. bigscience/bloom-1b7** \n",
        "\n",
        "##### **`Import the Model`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GOvqD5EEPDjr"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "MODEL_NAME = \"bigscience/bloom-1b7\"\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "story_topic = \"\"\"a Sandwich in Space as the protagonist and a cute Teddy Bear as the main villain\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **`Generate Stories with Varied Amount of Context`** \n",
        "\n",
        "**A. No Context**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = f\"\"\"This is a story about {story_topic}.\"\"\"\n",
        "\n",
        "\n",
        "encoded_prompt = tokenizer.encode(prompt, return_tensors='pt')\n",
        "story = model.generate(encoded_prompt, max_length=500, do_sample=True, temperature=0.7)\n",
        "\n",
        "\n",
        "bloom_story_A = tokenizer.decode(story[0], skip_special_tokens=True)\n",
        "print(bloom_story_A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**B. Previous Event**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "previous_event = bloom_story_A[-200:]\n",
        "previous_event"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = f\"\"\"In the story about {story_topic}, {previous_event}. What happened next?\"\"\"\n",
        "            \n",
        "\n",
        "encoded_prompt = tokenizer.encode(prompt, return_tensors='pt')\n",
        "story = model.generate(encoded_prompt, max_length=500, do_sample=True, temperature=0.7)\n",
        "\n",
        "\n",
        "bloom_story_B = tokenizer.decode(story[0], skip_special_tokens=True)\n",
        "print(bloom_story_B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**C. Summary of Previous Chapter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "text = bloom_story_A + bloom_story_B\n",
        "story_summary = summarizer(text, max_length=130, min_length=30, do_sample=False)[0]['summary_text']\n",
        "print(story_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = f\"\"\"In the story about {story_topic}, {story_summary}. What happened next?\"\"\"\n",
        "            \n",
        "encoded_prompt = tokenizer.encode(prompt, return_tensors='pt')\n",
        "story = model.generate(encoded_prompt, max_length=500, do_sample=True, temperature=0.7)\n",
        "\n",
        "\n",
        "bloom_story_C = tokenizer.decode(story[0], skip_special_tokens=True)\n",
        "print(bloom_story_C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "'''\n",
        "\n",
        "### **2. EleutherAI/gpt-neo-2.7B**\n",
        "\n",
        "##### **`Import the Model`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ee2917bdc9d445696c6fad4a4a6fd49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sanskar\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Sanskar\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e690a2cca626418a90458a39683532af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/10.7G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d995f63a14fb45f3bfc137e124cb6c1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "796a3904f56c4db9b87143cd9ec11d07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6d33f84a4e547c9aa55c12150271704",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3d67de88a5b4c5b9cd370caaa77c12c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "MODEL_NAME = \"EleutherAI/gpt-neo-2.7B\"\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "story_topic = \"\"\"a Sandwich in Space as the protagonist and a cute Teddy Bear as the main villain\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **`Generate Stories with Varied Amount of Context`**\n",
        "\n",
        "**A. No Context**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Sanskar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\distributions\\distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From C:\\Users\\Sanskar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\distributions\\bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "This is a story about a Sandwich in Space as the protagonist and a cute Teddy Bear as the main villain.\n",
            "\n",
            "The story is written in the third person point of view, with the protagonist being the narrator. This is a very unusual way to write a story. If you don’t understand why this is unusual I’ll explain it.\n",
            "\n",
            "You can read the first three sections more or less on my blog, and then the final section here.\n",
            "\n",
            "In the first section I make a list of things that have happened to the protagonist in their life.\n",
            "\n",
            "In the second section I explain the events of the story, and how they affect the protagonist’s life.\n",
            "\n",
            "In the final section I explain how the protagonist plans to deal with the actions of the antagonist.\n",
            "\n",
            "Now it is time to explain why the narrator is writing this story as the third person POV.\n",
            "\n",
            "The reason you are reading this story is because you have read the first two sections.\n",
            "\n",
            "I have explained that in the second section, the protagonist is writing this story. It is the third person POV because this is an action adventure story.\n",
            "\n",
            "So let me explain what it means to beigator in a story.\n",
            "\n",
            "It means that the protagonist is in control. They are in charge of what happens to them. The narrator is not telling the story. The protagonist is telling the story.\n",
            "\n",
            "In the first part of the story the protagonist is writing this story, and the narrator is just reading the story.\n",
            "\n",
            "The narrator is not writing the story, the protagonist is writing the story, and the narrator is just reading the story.\n",
            "\n",
            "In the second part of the story the protagonist has a number of things happen to them, and the narrator is just reading the story.\n",
            "\n",
            "The narrator is not writing the story, the protagonist is writing the story, and the narrator is just reading the story.\n",
            "\n",
            "In the third part of the story the protagonist has a number of things happen to them, and the narrator is writing the story.\n",
            "\n",
            "The narrator is writing the story, and the protagonist is just reading the story.\n",
            "\n",
            "In the fourth part of the story the protagonist has a number of things happen to them, and the narrator is writing the story.\n",
            "\n",
            "The narrator is writing the story, and the protagonist is just reading the story.\n",
            "\n",
            "In the fifth part of the story the protagonist has a number of\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"This is a story about {story_topic}.\"\"\"\n",
        "\n",
        "\n",
        "encoded_prompt = tokenizer.encode(prompt, return_tensors='pt')\n",
        "story = model.generate(encoded_prompt, max_length=500, do_sample=True, temperature=0.7)\n",
        "\n",
        "\n",
        "gpt_neo_story_A = tokenizer.decode(story[0], skip_special_tokens=True)\n",
        "print(gpt_neo_story_A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**B. Previous Event**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'appen to them, and the narrator is writing the story.\\n\\nThe narrator is writing the story, and the protagonist is just reading the story.\\n\\nIn the fifth part of the story the protagonist has a number of'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "previous_event = gpt_neo_story_A[-200:]\n",
        "previous_event"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the story about a Sandwich in Space as the protagonist and a cute Teddy Bear as the main villain, appen to them, and the narrator is writing the story.\n",
            "\n",
            "The narrator is writing the story, and the protagonist is just reading the story.\n",
            "\n",
            "In the fifth part of the story the protagonist has a number of. What happened next?\n",
            "\n",
            "The protagonist is writing the story, and the narrator is just reading the story.\n",
            "\n",
            "In the fifth part of the story the narrator is writing the story, and the protagonist is just reading the story.\n",
            "\n",
            "In the sixth part of the story the protagonist and the narrator have a short argument about the characters. The narrator thinks the protagonist is being too selfish, and the protagonist thinks the narrator is being too self-centered.\n",
            "\n",
            "The protagonist and the narrator argue about the characters, and the narrator thinks the protagonist is being too selfish, and the protagonist thinks the narrator is being too self-centered.\n",
            "\n",
            "In the seventh part of the story the narrator tells the protagonist the story of the sandwich in space.\n",
            "\n",
            "The narrator tells the protagonist the story of the sandwich in space.\n",
            "\n",
            "In the seventh part of the story the narrator tells the protagonist the story of the sandwich in space.\n",
            "\n",
            "In the seventh part of the story the narrator tells the protagonist the story of the sandwich in space.\n",
            "\n",
            "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
            "\n",
            "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
            "\n",
            "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
            "\n",
            "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
            "\n",
            "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
            "\n",
            "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
            "\n",
            "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
            "\n",
            "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
            "\n",
            "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
            "\n",
            "In the ninth part of the story the protagonist goes to a party.\n",
            "\n",
            "In the ninth part of the story the protagonist goes to a party.\n",
            "\n",
            "In the ninth part of the story the protagonist goes to a party.\n",
            "\n",
            "In the ninth part of the story the protagonist goes to\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"In the story about {story_topic}, {previous_event}. What happened next?\"\"\"\n",
        "            \n",
        "\n",
        "encoded_prompt = tokenizer.encode(prompt, return_tensors='pt')\n",
        "story = model.generate(encoded_prompt, max_length=500, do_sample=True, temperature=0.7)\n",
        "\n",
        "\n",
        "gpt_neo_story_B = tokenizer.decode(story[0], skip_special_tokens=True)\n",
        "print(gpt_neo_story_B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**C. Summary of Previous Chapter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a story about a Sandwich in Space as the protagonist and a cute Teddy Bear as the main villain. The story is written in the third person point of view, with the protagonist being the narrator. If you don’t understand why this is unusual I’ll explain it.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "text = gpt_neo_story_A + gpt_neo_story_B\n",
        "story_summary = summarizer(text, max_length=130, min_length=30, do_sample=False)[0]['summary_text']\n",
        "print(story_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the story about a Sandwich in Space as the protagonist and a cute Teddy Bear as the main villain, This is a story about a Sandwich in Space as the protagonist and a cute Teddy Bear as the main villain. The story is written in the third person point of view, with the protagonist being the narrator. If you don’t understand why this is unusual I’ll explain it.. What happened next?\n",
            "\n",
            "The story was written by me, and I’ve been told by many people that it’s unique, so I decided to post it here for whoever might be interested. But I don’t think it’s any good.\n",
            "\n",
            "As I’ve said, I don’t think it’s any good, because it’s not a story. It’s a series of short, simple, and not very interesting stories about a sandwich in space, the sandwiches having been sent there by a certain scientist.\n",
            "\n",
            "The first one was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that had a rocket in it. It was about a sandwich that travelled from one planet to another, and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"In the story about {story_topic}, {story_summary}. What happened next?\"\"\"\n",
        "            \n",
        "encoded_prompt = tokenizer.encode(prompt, return_tensors='pt')\n",
        "story = model.generate(encoded_prompt, max_length=500, do_sample=True, temperature=0.7)\n",
        "\n",
        "\n",
        "gpt_neo_story_C = tokenizer.decode(story[0], skip_special_tokens=True)\n",
        "print(gpt_neo_story_C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "'''\n",
        "\n",
        "### **3. databricks/dolly-v2-3b** \n",
        "\n",
        "##### **`Import the Model`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11f092a205ed48e28c63f65b3a3ee9dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/819 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sanskar\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Sanskar\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48c19b4d555f41019fe3508fbf4fb401",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6f0e070e141414b9ee9540ef3db1545",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/450 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2a74e8bab494de1852989c316f81603",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "825be4da8f9f499e9581de4cdbe64add",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "MODEL_NAME = \"databricks/dolly-v2-3b\"\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "story_topic = \"\"\"a Sandwich in Space as the protagonist and a cute Teddy Bear as the main villain\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **`Generate Stories with Varied Amount of Context`**\n",
        "\n",
        "**A. No Context**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Sanskar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\distributions\\distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From C:\\Users\\Sanskar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\distributions\\bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "This is a story about a Sandwich in Space as the protagonist and a cute Teddy Bear as the main villain.\n",
            "\n",
            "Chapter One: A Sandwich in Space\n",
            "\n",
            "It was a typical Sunday. The author was in the bedroom laying down reading when he heard a loud thump coming from his son's room. He got up to see his isoforms playing with his son's new Lego set. He walked over to his son and asked him what he was doing. His son responded that he was making a spaceship out of Legos. His father then asked him what he was going to do when he was done. His son responded that he wanted to go outside and play in the backyard. His father then asked him if he remembered what happened when he was a kid and how dangerous it could be. His son responded by saying that he didn't want to go back to being a kid, he wanted to stay a kid. His father then asked him why, to which his son responded that he liked being a kid and he didn't want to be a man. His father then asked him what \"man\" meant, to which his son responded by shrugging his shoulders and saying that he didn't know. His father then started to get frustrated and asked him to at least have an understanding for what man meant, to which his son responded by saying that he didn't care. His father then asked him again, to which his son responded by saying that he didn't want to talk about it anymore. His father then said that he thought that was the end of the matter and started to walk out of the room. As he was closing the door, he heard his son call out \"Dad, can I have my legos?\". He turned around to see his son standing there holding a broken Lego piece in his hand. His son asked him if he was going to give him a piece of his lego, to which his father responded by saying that he would not. His son then asked him why, to which his father responded by saying that he was going to give him a piece of his lego because he was his son and he was going to treat him the way he wanted to be treated. His son then asked him what that meant, to which his father responded by saying that he would use his best judgment. His son then said that he wanted his legos back, to which his father responded by saying that he would keep his legos and\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"This is a story about {story_topic}.\"\"\"\n",
        "\n",
        "\n",
        "encoded_prompt = tokenizer.encode(prompt, return_tensors='pt')\n",
        "story = model.generate(encoded_prompt, max_length=500, do_sample=True, temperature=0.7)\n",
        "\n",
        "\n",
        "dolly_story_A = tokenizer.decode(story[0], skip_special_tokens=True)\n",
        "print(dolly_story_A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**B. Previous Event**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "', to which his father responded by saying that he would use his best judgment. His son then said that he wanted his legos back, to which his father responded by saying that he would keep his legos and'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "previous_event = dolly_story_A[-200:]\n",
        "previous_event"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the story about a Sandwich in Space as the protagonist and a cute Teddy Bear as the main villain,, to which his father responded by saying that he would use his best judgment. His son then said that he wanted his legos back, to which his father responded by saying that he would keep his legos and. What happened next? His son got upset and shouted at his father.  His father explained that he meant he would use his best judgment based on the fact that he had not eaten his lunch yet. The son then said that he did not mean he was going to give him his legos, and his father said \"Oh I think you mean you want your legos back.\"  The son then said he wanted his legos back.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"In the story about {story_topic}, {previous_event}. What happened next?\"\"\"\n",
        "            \n",
        "\n",
        "encoded_prompt = tokenizer.encode(prompt, return_tensors='pt')\n",
        "story = model.generate(encoded_prompt, max_length=500, do_sample=True, temperature=0.7)\n",
        "\n",
        "\n",
        "dolly_story_B = tokenizer.decode(story[0], skip_special_tokens=True)\n",
        "print(dolly_story_B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**C. Summary of Previous Chapter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a story about a Sandwich in Space as the protagonist and a cute Teddy Bear as the main villain. The author was in the bedroom laying down reading when he heard a loud thump coming from his son's room. He turned around to see his son holding a broken Lego piece in his hand.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "text = dolly_story_A + dolly_story_B\n",
        "story_summary = summarizer(text, max_length=130, min_length=30, do_sample=False)[0]['summary_text']\n",
        "print(story_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the story about a Sandwich in Space as the protagonist and a cute Teddy Bear as the main villain, This is a story about a Sandwich in Space as the protagonist and a cute Teddy Bear as the main villain. The author was in the bedroom laying down reading when he heard a loud thump coming from his son's room. He turned around to see his son holding a broken Lego piece in his hand.. What happened next? Read it and find out..\n",
            "\n",
            "\"It was a beautiful day and I was walking through the park when I saw a small gray bear sitting by a tree. I walked up to see if it was a friendly bear and I asked the bear, \"Are you a friendly bear?\", to which the bear replied, \"I am a friendly bear, how are you?\". I then asked the bear, \"Do you have any food?\", to which the bear replied, \"I do, this is a very healthy diet. I am a vegetarian.\". I then asked the bear, \"Would you like to share your food with me?\", to which the bear replied, \"Of course, come to my home and share your food with me\". I then followed the bear to his home and he showed me his meal. I was very surprised by the meal and asked the bear, \"Where did you get the food from?\", to which the bear replied, \"I have a very healthy diet of vegetables and fruits. I do not eat meat\". I then asked the bear, \"Would you like to share your home with me?\", to which the bear replied, \"Of course, come to my home and we can live together\". We moved into his home and he showed me around, and told me that I could have as much food as I wanted. I had a very delicious meal and I was very happy. After dinner, I asked the bear, \"Would you like to have a bath and sleep in my bed?\", to which the bear replied, \"Of course, come to my bedroom and take a bath and sleep in my bed\". I then followed the bear to his bedroom and he showed me to my bed. I quickly changed into my pajamas, and after a short while, the bear came into the room and took a bath. After the bath, the bear took his pajamas off and joined me in the bed. We both fell fast asleep.\n",
            "\n",
            "After a few hours, I woke up and saw that the bear\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"In the story about {story_topic}, {story_summary}. What happened next?\"\"\"\n",
        "            \n",
        "encoded_prompt = tokenizer.encode(prompt, return_tensors='pt')\n",
        "story = model.generate(encoded_prompt, max_length=500, do_sample=True, temperature=0.7)\n",
        "\n",
        "\n",
        "dolly_story_C = tokenizer.decode(story[0], skip_special_tokens=True)\n",
        "print(dolly_story_C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***\n",
        "\n",
        "## **B. Exploring Effectiveness of Greater Context** <a id=\"4\"></a>\n",
        "\n",
        "* Let's now Explore the `effect` varied levels of `context` can effect the `Quality` of generated `story`.\n",
        "\n",
        "* Below are all the generated stories - "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "story_topic = \"\"\"a Sandwich in Space as the protagonist and a cute Teddy Bear as the main villain\"\"\"\n",
        "\n",
        "bloom_story_A = \"\"\"The story is about a little boy named Rux, who is a little geeky and loves to watch \n",
        "TV shows. He lives in a small village, and when he sees a मूलभूत video on the TV and \n",
        "is curious about the what it is about, he decides to start watching the video. The \n",
        "video goes on to tell him about the Sandwich in Space, and how he and his friends \n",
        "have to go back to the Sandwich in Space to find their way home. He is a little \n",
        "scared, but his friends convince him that they will go along with him to the Sandwich \n",
        "in Space.\n",
        "            The Sandwich in Space is a large, dome-shaped, space-like object. It is \n",
        "made of a glass and a metal core. It has four doors, and the doors have a small hole \n",
        "in the center, so that the Sandwich in Space can be opened and closed. The core of \n",
        "the Sandwich in Space is made of some metal or other substance that is solid and hard \n",
        "and has chake, a large glass sphere on the top and a glass dome on either end of the \n",
        "core. The doors of the Sandwich in Space can be opened by turning the core, but can be \n",
        "closed by turning the glass dome. The doors are attached to the core with a small \n",
        "metal wire. The doors of the Sandwich in Space are made of some material that is hard \n",
        "and has a slight indentation in the middle. The dome of the Sandwich inરાવ is made of \n",
        "some material that is harder and has a slightly more indented middle.\"\"\"\n",
        "\n",
        "bloom_story_B = \"\"\"The dome started to melt. At first رأه it was a small, red dome. Then it grew bigger \n",
        "and bigger and started to melt: it was a huge dome. Then it started to expand and \n",
        "expand and start to expand. senses. The dome had a great effect on the protagonist, \n",
        "so the protagonist decided to take it. The dome was a big sphere with a transparent \n",
        "dome. The dome was covered with a plastic dome. The dome had a small ball shaped dome. \n",
        "The dome had a large dome with a cabellike dome. The dome had a small dome with सम्भled \n",
        "dome. The dome had a dome with a spherical dome. The dome had a dome with a Valencian \n",
        "version of the story. In the story about a Sandwich in Space as the protagonist and a cute \n",
        "Teddy Bear apur the main villain, ached to the core and the dome. The core is attached to the \n",
        "glass sphere and the dome with a metal ring and the core and the dome have a small metal wire \n",
        "that is attached to the core and the dome. The dome was a big sphere with a transparent dome. \n",
        "The dome was covered with a plastic dome. The dome had a small ball shaped dome. The \n",
        "dome had a large dome with a cabellike dome. \"\"\"\n",
        "\n",
        "bloom_story_summary = \"\"\"The Sandwich in Space is a large, dome-shaped, space-like object. It is made of a \n",
        "glass and a metal core. It has four doors, and the doors have a small hole in the center. The doors \n",
        "are attached to the core with a small metal wire.\"\"\"\n",
        "\n",
        "bloom_story_C = \"\"\"The Sandwich in Space was a movie, a cartoon, a book, a television series or a comic \n",
        "book, or a video game. It was a space movie with a touch of science fiction. The Sandwich in Space was a \n",
        "space movie with a touch of science fiction. This film was released on August 25, 2003. The Sandwich in \n",
        "Space was a space movie with a touch of science fiction. This film was released on August 25, 2003. It was \n",
        "a space movie with a touch of science fiction. This film was released on August 25, 2003. The Sandwich in \n",
        "Space was a space movie with a touch of science fiction. This film was released on August 25, 2003. This \n",
        "film was released on August 25, 2003. The Sandwich in Space was a space movie with a touch of science \n",
        "fiction. This film was released on August 25, 2003. The Sandwich in Space quelle taille est le sandwich \n",
        "dans l'espace. The Sandwich in Space quelle taille est le sandwich dans l'espace. Skip to main content. \n",
        "Try Prime EN Hello, Sign in Account & Lists Sign in Account & Lists Orders Try Prime Cart.ographiques du \n",
        "Royaume-Uni / Londres.\n",
        "                        The Sandwich in Space is a space movie with a touch of science fiction. It is a \n",
        "dome-shaped, space-like object. It has four doors, and the doors have a small hole in the center. The \n",
        "doors are attached to the core with a small metal wire.. What happened next? Watch The ఆధ్వరe du sandwich \n",
        "dans l'espace. The Sandwich in Space is kemampuan yang diberikan oleh Tuhan kepada manusia. The Sandwich \n",
        "in Space is ability given by God to the human. The Sandwich in Space is ability given by God to the human. \n",
        "The Sandwich in Space is ability given by God to the human. The Sandwich in Space is ability given by God \n",
        "to the human. The Sandwich in Space is ability given by God to the human. The Sandwich in Space is ability \n",
        "given by God to the human. The Sandwich in Space is ability\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "gpt_neo_story_A = \"\"\"The story is written in the third person point of view, with the protagonist being the narrator. \n",
        "This is a very unusual way to write a story. If you don’t understand why this is unusual I’ll explain it.\n",
        "\n",
        "You can read the first three sections more or less on my blog, and then the final section here.\n",
        "\n",
        "In the first section I make a list of things that have happened to the protagonist in their life.\n",
        "\n",
        "In the second section I explain the events of the story, and how they affect the protagonist’s life.\n",
        "\n",
        "In the final section I explain how the protagonist plans to deal with the actions of the antagonist.\n",
        "\n",
        "Now it is time to explain why the narrator is writing this story as the third person POV.\n",
        "\n",
        "The reason you are reading this story is because you have read the first two sections.\n",
        "\n",
        "I have explained that in the second section, the protagonist is writing this story. It is the third person POV \n",
        "because this is an action adventure story.\n",
        "\n",
        "So let me explain what it means to beigator in a story.\n",
        "\n",
        "It means that the protagonist is in control. They are in charge of what happens to them. The narrator is not \n",
        "telling the story. The protagonist is telling the story.\n",
        "\n",
        "In the first part of the story the protagonist is writing this story, and the narrator is just reading the \n",
        "story.\n",
        "\n",
        "The narrator is not writing the story, the protagonist is writing the story, and the narrator is just reading \n",
        "the story.\n",
        "\n",
        "In the second part of the story the protagonist has a number of things happen to them, and the narrator is \n",
        "just reading the story.\n",
        "\n",
        "The narrator is not writing the story, the protagonist is writing the story, and the narrator is just \n",
        "reading the story.\n",
        "\n",
        "In the third part of the story the protagonist has a number of things happen to them, and the narrator is \n",
        "writing the story.\n",
        "\n",
        "The narrator is writing the story, and the protagonist is just reading the story.\n",
        "\n",
        "In the fourth part of the story the protagonist has a number of things happen to them, and the narrator is \n",
        "writing the story.\n",
        "\n",
        "The narrator is writing the story, and the protagonist is just reading the story.\n",
        "\n",
        "In the fifth part of the story the protagonist has a number of\"\"\"\n",
        "\n",
        "gpt_neo_story_B = \"\"\"The narrator is writing the story, and the protagonist is just reading the story.\n",
        "\n",
        "In the fifth part of the story the protagonist has a number of. What happened next?\n",
        "\n",
        "The protagonist is writing the story, and the narrator is just reading the story.\n",
        "\n",
        "In the fifth part of the story the narrator is writing the story, and the protagonist is just reading the \n",
        "story.\n",
        "\n",
        "In the sixth part of the story the protagonist and the narrator have a short argument about the characters. \n",
        "The narrator thinks the protagonist is being too selfish, and the protagonist thinks the narrator is being \n",
        "too self-centered.\n",
        "\n",
        "The protagonist and the narrator argue about the characters, and the narrator thinks the protagonist is \n",
        "being too selfish, and the protagonist thinks the narrator is being too self-centered.\n",
        "\n",
        "In the seventh part of the story the narrator tells the protagonist the story of the sandwich in space.\n",
        "\n",
        "The narrator tells the protagonist the story of the sandwich in space.\n",
        "\n",
        "In the seventh part of the story the narrator tells the protagonist the story of the sandwich in space.\n",
        "\n",
        "In the seventh part of the story the narrator tells the protagonist the story of the sandwich in space.\n",
        "\n",
        "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
        "\n",
        "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
        "\n",
        "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
        "\n",
        "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
        "\n",
        "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
        "\n",
        "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
        "\n",
        "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
        "\n",
        "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
        "\n",
        "In the eighth part of the story the protagonist is eating the sandwich in space.\n",
        "\n",
        "In the ninth part of the story the protagonist goes to a party.\n",
        "\n",
        "In the ninth part of the story the protagonist goes to a party.\n",
        "\n",
        "In the ninth part of the story the protagonist goes to a party.\n",
        "\n",
        "In the ninth part of the story the protagonist goes to\"\"\"\n",
        "\n",
        "gpt_neo_story_summary = \"\"\"This is a story about a Sandwich in Space as the protagonist and a cute Teddy Bear \n",
        "                    as the main villain. The story is written in the third person point of view, with \n",
        "                    the protagonist being the narrator. If you don’t understand why this is unusual I’ll \n",
        "                    explain it.\"\"\"\n",
        "\n",
        "gpt_neo_story_C = \"\"\"The story was written by me, and I’ve been told by many people that it’s unique, so I\n",
        "decided to post it here for whoever might be interested. But I don’t think it’s any good.\n",
        "\n",
        "As I’ve said, I don’t think it’s any good, because it’s not a story. It’s a series of short, simple, and \n",
        "not very interesting stories about a sandwich in space, the sandwiches having been sent there by a certain \n",
        "scientist.\n",
        "\n",
        "The first one was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich \n",
        "that had a rocket in it. It was about a sandwich that travelled from one planet to another, and ate \n",
        "sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was about a \n",
        "sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in a \n",
        "rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It was \n",
        "about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled in \n",
        "a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It \n",
        "was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled \n",
        "in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It \n",
        "was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled \n",
        "in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It \n",
        "was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled \n",
        "in a rocket and ate sandwiches. It was about a sandwich that travelled in a rocket and ate sandwiches. It \n",
        "was about a sandwich that travelled in a rocket and ate sandwiches. It was about a sandwich that travelled \n",
        "in a rocket and ate sandwiches.\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dolly_story_A = \"\"\"Chapter One: A Sandwich in Space\n",
        "\n",
        "It was a typical Sunday. The author was in the bedroom laying down reading when he heard a loud thump \n",
        "coming from his son's room. He got up to see his isoforms playing with his son's new Lego set. He walked \n",
        "over to his son and asked him what he was doing. His son responded that he was making a spaceship out of \n",
        "Legos. His father then asked him what he was going to do when he was done. His son responded that he \n",
        "wanted to go outside and play in the backyard. His father then asked him if he remembered what happened \n",
        "when he was a kid and how dangerous it could be. His son responded by saying that he didn't want to go \n",
        "back to being a kid, he wanted to stay a kid. His father then asked him why, to which his son responded \n",
        "that he liked being a kid and he didn't want to be a man. His father then asked him what \"man\" meant, to \n",
        "which his son responded by shrugging his shoulders and saying that he didn't know. His father then started \n",
        "to get frustrated and asked him to at least have an understanding for what man meant, to which his son \n",
        "responded by saying that he didn't care. His father then asked him again, to which his son responded by \n",
        "saying that he didn't want to talk about it anymore. His father then said that he thought that was the \n",
        "end of the matter and started to walk out of the room. As he was closing the door, he heard his son call \n",
        "out \"Dad, can I have my legos?\". He turned around to see his son standing there holding a broken Lego \n",
        "piece in his hand. His son asked him if he was going to give him a piece of his lego, to which his father \n",
        "responded by saying that he would not. His son then asked him why, to which his father responded by saying \n",
        "that he was going to give him a piece of his lego because he was his son and he was going to treat him \n",
        "the way he wanted to be treated. His son then asked him what that meant, to which his father responded by \n",
        "saying that he would use his best judgment. His son then said that he wanted his legos back, to which his \n",
        "father responded by saying that he would keep his legos and\"\"\"\n",
        "\n",
        "dolly_story_B = \"\"\"In the story about a Sandwich in Space as the protagonist and a cute Teddy Bear as the \n",
        "main villain,, to which his father responded by saying that he would use his best judgment. His son then \n",
        "aid that he wanted his legos back, to which his father responded by saying that he would keep his legos \n",
        "and. What happened next? His son got upset and shouted at his father.  His father explained that he meant \n",
        "he would use his best judgment based on the fact that he had not eaten his lunch yet. The son then said \n",
        "that he did not mean he was going to give him his legos, and his father said \"Oh I think you mean you want \n",
        "your legos back.\"  The son then said he wanted his legos back.\"\"\"\n",
        "\n",
        "dolly_story_summary = \"\"\"This is a story about a Sandwich in Space as the protagonist and a cute Teddy Bear as \n",
        "the main villain. The author was in the bedroom laying down reading when he heard a loud thump coming from \n",
        "his son's room. He turned around to see his son holding a broken Lego piece in his hand.\"\"\"\n",
        "\n",
        "dolly_story_C = \"\"\"\"It was a beautiful day and I was walking through the park when I saw a small gray bear \n",
        "sitting by a tree. I walked up to see if it was a friendly bear and I asked the bear, \"Are you a friendly \n",
        "bear?\", to which the bear replied, \"I am a friendly bear, how are you?\". I then asked the bear, \"Do you \n",
        "have any food?\", to which the bear replied, \"I do, this is a very healthy diet. I am a vegetarian.\". I \n",
        "then asked the bear, \"Would you like to share your food with me?\", to which the bear replied, \"Of course, \n",
        "come to my home and share your food with me\". I then followed the bear to his home and he showed me his \n",
        "meal. I was very surprised by the meal and asked the bear, \"Where did you get the food from?\", to which \n",
        "the bear replied, \"I have a very healthy diet of vegetables and fruits. I do not eat meat\". I then asked \n",
        "the bear, \"Would you like to share your home with me?\", to which the bear replied, \"Of course, come to my \n",
        "home and we can live together\". We moved into his home and he showed me around, and told me that I could \n",
        "have as much food as I wanted. I had a very delicious meal and I was very happy. After dinner, I asked the \n",
        "bear, \"Would you like to have a bath and sleep in my bed?\", to which the bear replied, \"Of course, come to \n",
        "my bedroom and take a bath and sleep in my bed\". I then followed the bear to his bedroom and he showed me \n",
        "to my bed. I quickly changed into my pajamas, and after a short while, the bear came into the room and took \n",
        "a bath. After the bath, the bear took his pajamas off and joined me in the bed. We both fell fast asleep.\n",
        "\n",
        "After a few hours, I woke up and saw that the bear\"\"\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "'''\n",
        "\n",
        "### **Evaluating using `Human Evaluation`**\n",
        "\n",
        "* Through Human Evaluation, we can come to the following conclusions - \n",
        "\n",
        "1. Using `Past Events` as Context is `not relaible`.\n",
        "\n",
        "2. Using `Story Summary` provides more context for generating `better stories`.\n",
        "\n",
        "* Since, summary takes in a major or all of the part of the story, it provides `Greater Context`, greatly `increasing Quality` of the generated `Story`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
