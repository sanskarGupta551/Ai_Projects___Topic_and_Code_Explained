{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Ai Imagining Stories from Images](#1)\n",
    "    * [A. Project Explained](#2)\n",
    "    * [B. Demonstration using Pre-trained models](#3)\n",
    "    * [C. Applications](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ai Imagining Stories from Images** <a id=\"1\"></a> \n",
    "\n",
    "> ### ***`A picture is worth a Thousand words.`***\n",
    "\n",
    "![Image](https://cdn.dribbble.com/users/1731254/screenshots/11649852/media/5551243bcbf041d5aa0b30abb6168215.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## **A. Project Explained** <a id=\"2\"></a>\n",
    "\n",
    "#### **Objective**\n",
    "\n",
    "* In this project, we will develop an `AI` system that can `generate` imaginative and engaging `stories` based on `input` `images`.\n",
    "\n",
    "'''\n",
    "\n",
    "#### **Workflow**\n",
    "\n",
    "We will build the `AI` system using `2` main components - \n",
    "\n",
    "##### **`1. Image Captioner -`** \n",
    "\n",
    "* This component involves using a Deep Learning model (like a Convolutional Neural Network) to `Extract Features` and understand the `Context` of the `Image`. \n",
    "* This could involve `recognizing` objects, people, settings, and emotions in the `Image`.\n",
    "* The `context` of the Image is then output as `Caption`.\n",
    "\n",
    "##### **`2. Story Generator -`** \n",
    "\n",
    "* This component involves using another model (like a Recurrent Neural Network or Transformer) to `Generate a Story` based on the `Caption` geneerated by the Image Captioner. \n",
    "* The `story` should be coherent, engaging, and `relevant` to the `image`.\n",
    "\n",
    ".\n",
    "\n",
    "Hence, the complete worklow would be - \n",
    "\n",
    "* ##### **`Input`** (Image) >>> **`Image Captioner`** >>> Caption >>> **`Story Generator`** >>> Story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## **B. Demonstration using Pre-trained models** <a id=\"3\"></a>\n",
    "\n",
    "* Let's demonstrate this idea using Pre-trained models.\n",
    "\n",
    "#### **`1. Image Captioner`**\n",
    "\n",
    "* We will use [nlpconnect/vit-gpt2-image-captioning](https://huggingface.co/nlpconnect/vit-gpt2-image-captioning) model from [hugging face](https://huggingface.co/) for this demonstration of an `Image Captioner`. \n",
    "\n",
    "* [nlpconnect/vit-gpt2-image-captioning](https://huggingface.co/nlpconnect/vit-gpt2-image-captioning) is a model that can generate text captions for images using `transformers`. It is based on the `Vision Transformer` (ViT) and the `Generative Pretrained Transformer 2` (GPT2) architectures. \n",
    "\n",
    "![Image](https://ankur3107.github.io/assets/images/vision-encoder-decoder.png)\n",
    "\n",
    "* The model was trained by `@ydshieh` in flax and converted to pytorch by `@ankur310794`. \n",
    "\n",
    "##### `Shoutout` to these wonderful people.\n",
    "\n",
    "* The model is available for `free` on [hugging face](https://huggingface.co/) and we can use this model to describe the `content` of any image in natural language. \n",
    "\n",
    "Let's import the model and inference it - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sanskar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\distributions\\distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From C:\\Users\\Sanskar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\distributions\\bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "C:\\Users\\Sanskar\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "model_name = \"nlpconnect/vit-gpt2-image-captioning\" \n",
    "captioner = pipeline(\"image-to-text\", model=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we will generate captions using this Model on the image below - \n",
    "\n",
    "![Image](https://www.pixelstalk.net/wp-content/uploads/2016/08/Funny-Random-Wallpaper-1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanskar\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\generation\\utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Caption : a painting of a bear and a statue of a cat \n"
     ]
    }
   ],
   "source": [
    "image = \"Funny-Random-Wallpaper-1.jpg\" \n",
    "\n",
    "\n",
    "result = captioner(image)\n",
    "print(f\"Generated Caption : {result[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `\"a painting of a bear and a statue of a cat\"`.\n",
    "\n",
    "* Well, `half right`. But considering the `model` was `trained` on real-life `images` captured by camera, this is still good enough for a `demonstration`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`2. Story Generator`**\n",
    "\n",
    "* Now, for demonstrating `Story Generator`, we will use [pranavpsv/gpt2-genre-story-generator](https://huggingface.co/pranavpsv/gpt2-genre-story-generator) model from [hugging face](https://huggingface.co/). \n",
    "\n",
    "* The [pranavpsv/gpt2-genre-story-generator](https://huggingface.co/pranavpsv/gpt2-genre-story-generator) model from huggingface is a `Text Generation` model that can create stories based on different `genres` and `prompts`. \n",
    "\n",
    "* It is a `fine-tuned` version of the `GPT-2` model, which is a large-scale language model that can generate coherent and diverse texts. \n",
    "\n",
    "* The model supports the following `genres`: superhero, action, drama, horror, thriller, and sci_fi. \n",
    "\n",
    "##### `Big thanks to the creator.`\n",
    "\n",
    "\n",
    "Let's import the model and inference it - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "model_name = \"pranavpsv/gpt2-genre-story-generator\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's use the `caption` generated as the prompt for generating story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a painting of a bear and a statue of a cat  The film opens with a scene of an elderly couple, Mrs and Mrs Pappas, reminiscing about their previous visit to the Pappas house. The Pappas are a very nice couple and are extremely fond of the house, especially the cat statue. The Pappas ask Mrs Pappas to take some pictures of the house in preparation to sell it. The Pappas are very keen on the house, and want to sell it, and the Pappas ask the Pappas to leave the house when they make the final decision. But the Pappas refuse to do so, and then Mrs Pappas tells them that they cannot sell the house. The Pappas then go out to buy some butter for the house as they cannot afford to buy a sweeper. The Pappas then go to the market and buy a car, despite the Pappas' protestations that they cannot afford an electric car. The Pappas then go back to Mrs Pappas' house and ask her for a divorce. Mrs nested the argument and asks the Pappas to leave the house. The Pappas refused to do so and then\n"
     ]
    }
   ],
   "source": [
    "prompt = result[0]['generated_text']\n",
    "\n",
    "\n",
    "inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "outputs = model.generate(inputs, max_length=250, do_sample=True, temperature=0.7)\n",
    "\n",
    "\n",
    "story = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `\"a painting of a bear and a statue of a cat  The film opens with a scene of an elderly couple, Mrs and Mrs Pappas, reminiscing about their previous visit to the Pappas house. The Pappas are a very nice couple and are extremely fond of the house, especially the cat statue. The Pappas ask Mrs Pappas to take some pictures of the house in preparation to sell it. The Pappas are very keen on the house, and want to sell it, and the Pappas ask the Pappas to leave the house when they make the final decision. But the Pappas refuse to do so, and then Mrs Pappas tells them that they cannot sell the house. The Pappas then go out to buy some butter for the house as they cannot afford to buy a sweeper. The Pappas then go to the market and buy a car, despite the Pappas' protestations that they cannot afford an electric car. The Pappas then go back to Mrs Pappas' house and ask her for a divorce. Mrs nested the argument and asks the Pappas to leave the house. The Pappas refused to do so and then\"`\n",
    "\n",
    "\n",
    "* The model performed good in generating a `contextual` and `coherent` story. \n",
    "\n",
    "* This is one way to imagine `stories` from `Images`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## **C. Applications**  <a id=\"4\"></a>\n",
    "#### **`Recording, Understanding and Predicting Events`**\n",
    "\n",
    "* This type of `AI system` can have many applications in the practical world.\n",
    "\n",
    "* The AI can be used for **`recording`**, **`understanding`** and **`predicting`** many events, such as - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Migration of Civilization** \n",
    "\n",
    "* People and `Civilizations` have always `migrated` from one place to another in search of food, resources, conquest of land, etc.\n",
    "\n",
    "* We can `monitor` and `understand` these trends, then try to `predict` possible migration in both \n",
    "`imminent` and `distant` future through `satellite images` to either `facilitate growth` of civilization or `prevent` any unseen `disaster`.\n",
    "\n",
    "![Image](https://si.wsj.net/public/resources/images/B3-EE969_ICONS0_SOC_20190606174717.jpg)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Climate Change and Natural Disasters** \n",
    "\n",
    "* Climate change is a big global `threat` to humanity. \n",
    "\n",
    "* Extreme `heat waves`, floods, hurricanes, `rivers` and lakes `drying` up leaving behind `arid` land, forest `fires`, `rise` in `ocean levels`, these are just a few effects of Climate change costing irreversible `damage` to `ecosystem` and costing us in `billions` financially.\n",
    "\n",
    "* We can `predict`, `prevent` and scale down the `impact` of many effects caused by Climate change by a large extent.\n",
    "\n",
    "![Image](https://images.axios.com/fQsbMgphvAVzvkvZDJIfIuXF4Vo=/2019/05/20/1558387426952.png)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Possible Life on Other Planets** \n",
    "\n",
    "* `Billions` of `stars` most with many `planets` each with possible `life` forms either `carbon based` or in `other` forms.\n",
    "\n",
    "* Ai can help us quickly `scan` through different `planets` in search for those teeming with `life` and explain their `evolution` and `characteristics`.\n",
    "\n",
    "![Image](https://www.icr.org/i/articles/af/can_life_exist_wide.jpg)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Military Build-ups** \n",
    "\n",
    "* `Provocative` or sneaky `Military` build-ups within or outside one's `border` which if left `unchecked` can pose a national `security threat` by giving the enemy an upper hand.\n",
    "\n",
    "* Ai can help us `track` such `build-ups`, `understand` their strengths and `weaknesses`, `predict` their actions and intentions better, and help us `counter-act` against them.\n",
    "\n",
    "![Image](https://content.api.news/v3/images/bin/3ba11a77dc6428a09c826403b54b9fa1)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Shifting of Water Bodies** \n",
    "\n",
    "* There is a lot of `evidence` that places now `deserted` once had a flourishing `green ecosystem` with `lakes` and `rivers` that have now been `dried` up.\n",
    "\n",
    "* Ai can help us `understand` the sequence of `events` that precisely led to the current day situation.\n",
    "\n",
    "![Image](https://cdn-academy.pressidium.com/academy/wp-content/uploads/2021/10/deltas.png)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Events in Cosmos** \n",
    "\n",
    "* `Universe expanding`, Primordial `gravity waves`, Quasars, Death and Birth of `stars`, formation of `planets` and `moons`, Collision of `black holes`. Talk about making a `cosmic ripple`.\n",
    "\n",
    "* Ai can help `track` and `predict` them all as well as `explain` better what could have caused certain `events`.\n",
    "\n",
    "![Image](https://static.businessinsider.com/image/545d3c406da81136606c8d43/image.jpg)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7. Evolution from Fossils** \n",
    "\n",
    "* The fossil record provides `snapshots` of the `past` which, when assembled, illustrate a panorama of `evolutionary change` over the past `3.5 billion years`. \n",
    "\n",
    "* The `image` may be smudged in places and has bits missing, but fossil `evidence` clearly shows that `life` is very, `very old` and has changed over time through `evolution`.\n",
    "\n",
    "* Ai can help `track` this `evolution` and `predict` what's to come.\n",
    "\n",
    "![Image](https://image.slideserve.com/311794/fossils-and-evolution-l.jpg)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **8. Orthography**\n",
    "\n",
    "* Orthography is the `practice` or `study` of correct `spelling` according to established usage. In a broader sense, orthography can refer to the `study of letters` and how they are used to express sounds and form words. \n",
    "\n",
    "* Ai can help us `fastrack` this process with `accurate` understaing and prediction of what `ancient languages` and `accents` sound like.\n",
    "\n",
    "![Image](https://1.bp.blogspot.com/-QBcuckhPfLg/X8gPV2B4NUI/AAAAAAAADqE/Ek7zplTmxkgTexDe2rhZxmN17iCpBnOOwCLcBGAsYHQ/s2048/1%2Bto%2B100%2BLakota%2Bcounting.jpg)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Conclusion`**\n",
    "\n",
    "* An Ai that can `generate context` and `derive events` from any `image` through experience on trained data can be a blessing in disguise and can help us `solve` a lot of real world `practical problems`.\n",
    "\n",
    "* It's an `untapped potential` that can help us progress to `space` and beyond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
